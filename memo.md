# Knowledge Distillation

## Concept
- Base Line : ResNet18 
- Offline KD : Teacher(ResNet50)
- Online KD : Teatcher(ResNet50)
- Self KD : ResBet18

- Dataset : CIFAR10

- With subset augmentation
- W/O subset augmentation